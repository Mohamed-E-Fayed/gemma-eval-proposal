@article{gemma2025gemma3,
title={Gemma 3 Technical Report},
    authors={Gemma Team Google DeepMind},
    year={2025},
        month={March},
}
@article{huang2023mlagentbench,
  title={Mlagentbench: Evaluating language agents on machine learning experimentation},
  author={Huang, Qian and Vora, Jian and Liang, Percy and Leskovec, Jure},
  journal={arXiv preprint arXiv:2310.03302},
  year={2023}
}
@article{yang2024swe,
  title={Swe-agent: Agent-computer interfaces enable automated software engineering},
  author={Yang, John and Jimenez, Carlos and Wettig, Alexander and Lieret, Kilian and Yao, Shunyu and Narasimhan, Karthik and Press, Ofir},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={50528--50652},
  year={2024}
}
@article{nathani2025mlgym,
  title={MLGym: A New Framework and Benchmark for Advancing AI Research Agents},
  author={Nathani, Deepak and Madaan, Lovish and Roberts, Nicholas and Bashlykov, Nikolay and Menon, Ajay and Moens, Vincent and Budhiraja, Amar and Magka, Despoina and Vorotilov, Vladislav and Chaurasia, Gaurav and others},
  journal={arXiv preprint arXiv:2502.14499},
  year={2025}
}

@article{post2018call,
  title={A call for clarity in reporting BLEU scores},
  author={Post, Matt},
  journal={arXiv preprint arXiv:1804.08771},
  year={2018}
}
@inproceedings{vedantam2015cider,
  title={Cider: Consensus-based image description evaluation},
  author={Vedantam, Ramakrishna and Lawrence Zitnick, C and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4566--4575},
  year={2015}
}
@inproceedings{lin2004rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}
@article{sellam2020bleurt,
  title={BLEURT: Learning robust metrics for text generation},
  author={Sellam, Thibault and Das, Dipanjan and Parikh, Ankur P},
  journal={arXiv preprint arXiv:2004.04696},
  year={2020}
}

@article{kantharaj2022chart,
  title={Chart-to-text: A large-scale benchmark for chart summarization},
  author={Kantharaj, Shankar and Leong, Rixie Tiffany Ko and Lin, Xiang and Masry, Ahmed and Thakkar, Megh and Hoque, Enamul and Joty, Shafiq},
  journal={arXiv preprint arXiv:2203.06486},
  year={2022}
}
@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}
@article{herzig2020tapas,
  title={TaPas: Weakly supervised table parsing via pre-training},
  author={Herzig, Jonathan and Nowak, Pawe{\l} Krzysztof and M{\"u}ller, Thomas and Piccinno, Francesco and Eisenschlos, Julian Martin},
  journal={arXiv preprint arXiv:2004.02349},
  year={2020}
}

@article{dsouza2022,
    author={Ashlyn DSouza and Kavish Gandhi and Bruce Walker},
    title={Graph Ingestion Engine Project Report, Fall 2022},
    year={2022},
}
@article{dsouza2023,
author={Ashlin DSouza and Bruce Walker},
    title={Graph Ingestion Engine Project Report, Spring 2023},
year={2023},
}
@article{liu2022deplot,
  title={Deplot: One-shot visual language reasoning by plot-to-table translation},
  author={Liu, Fangyu and Eisenschlos, Julian Martin and Piccinno, Francesco and Krichene, Syrine and Pang, Chenxi and Lee, Kenton and Joshi, Mandar and Chen, Wenhu and Collier, Nigel and Altun, Yasemin},
  journal={arXiv preprint arXiv:2212.10505},
  year={2022}
}
@article{masry2022chartqa,
  title={Chartqa: A benchmark for question answering about charts with visual and logical reasoning},
  author={Masry, Ahmed and Long, Do Xuan and Tan, Jia Qing and Joty, Shafiq and Hoque, Enamul},
  journal={arXiv preprint arXiv:2203.10244},
  year={2022}
}
@article{xia2024chartx,
  title={Chartx \& chartvlm: A versatile benchmark and foundation model for complicated chart reasoning},
  author={Xia, Renqiu and Zhang, Bo and Ye, Hancheng and Yan, Xiangchao and Liu, Qi and Zhou, Hongbin and Chen, Zijun and Dou, Min and Shi, Botian and Yan, Junchi and others},
  journal={arXiv preprint arXiv:2402.12185},
  year={2024}
}
@inproceedings{wang2024mmlu,
  title={Mmlu-pro: A more robust and challenging multi-task language understanding benchmark},
  author={Wang, Yubo and Ma, Xueguang and Zhang, Ge and Ni, Yuansheng and Chandra, Abhranil and Guo, Shiguang and Ren, Weiming and Arulraj, Aaran and He, Xuan and Jiang, Ziyan and others},
  booktitle={The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2024}
}
@article{saikh2022scienceqa,
  title={Scienceqa: A novel resource for question answering on scholarly articles},
  author={Saikh, Tanik and Ghosal, Tirthankar and Mittal, Amish and Ekbal, Asif and Bhattacharyya, Pushpak},
  journal={International Journal on Digital Libraries},
  volume={23},
  number={3},
  pages={289--301},
  year={2022},
  publisher={Springer}
}
@article{lin2021truthfulqa,
  title={Truthfulqa: Measuring how models mimic human falsehoods},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  journal={arXiv preprint arXiv:2109.07958},
  year={2021}
}
@article{srivastava2023beyond,
  title={Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models},
  author={BIG-bench authors},
  journal={Transactions on Machine Learning Research},
  issn={2835-8856},
  year={2023},
  url={https://openreview.net/forum?id=uyTL5Bvosj},
  note={}
}
@article{zellers2019hellaswag,
  title={Hellaswag: Can a machine really finish your sentence?},
  author={Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
  journal={arXiv preprint arXiv:1905.07830},
  year={2019}
}
@article{li2025hellaswag,
  title={HellaSwag-Pro: A Large-Scale Bilingual Benchmark for Evaluating the Robustness of LLMs in Commonsense Reasoning},
  author={Li, Xiaoyuan and Li, Moxin and Men, Rui and Zhang, Yichang and Bao, Keqin and Wang, Wenjie and Feng, Fuli and Liu, Dayiheng and Lin, Junyang},
  journal={arXiv preprint arXiv:2502.11393},
  year={2025}
}
@article{zhou2023instruction,
  title={Instruction-following evaluation for large language models},
  author={Zhou, Jeffrey and Lu, Tianjian and Mishra, Swaroop and Brahma, Siddhartha and Basu, Sujoy and Luan, Yi and Zhou, Denny and Hou, Le},
  journal={arXiv preprint arXiv:2311.07911},
  year={2023}
}
@article{kovalevskyi2024ifeval,
  title={IFEval-Extended: Enhancing Instruction-Following Evaluation in Large Language Models through Dynamic Prompt Generation},
  author={Kovalevskyi, Bohdan},
  journal={Journal of Artificial Intelligence General science (JAIGS) ISSN: 3006-4023},
  volume={5},
  number={1},
  pages={513--524},
  year={2024}
}
@article{xuan2025mmlu,
  title={MMLU-ProX: A Multilingual Benchmark for Advanced Large Language Model Evaluation},
  author={Xuan, Weihao and Yang, Rui and Qi, Heli and Zeng, Qingcheng and Xiao, Yunze and Xing, Yun and Wang, Junjue and Li, Huitao and Li, Xin and Yu, Kunyu and others},
  journal={arXiv preprint arXiv:2503.10497},
  year={2025}
}
@article{chen2024structtest,
  title={StructTest: Benchmarking LLMs' Reasoning through Compositional Structured Outputs},
  author={Chen, Hailin and Jiao, Fangkai and Ravaut, Mathieu and Farruque, Nawshad and Nguyen, Xuan Phi and Qin, Chengwei and Dey, Manan and Ding, Bosheng and Xiong, Caiming and Joty, Shafiq and others},
  journal={arXiv preprint arXiv:2412.18011},
  year={2024}
}

@misc{hf-openllmleaderboard,
    title={Open LLM Leaderboard},
    authors={Hugging Face},
    url={https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard#/},
}
@misc{eval-harness,
  author       = {Gao, Leo and Tow, Jonathan and Abbasi, Baber and Biderman, Stella and Black, Sid and DiPofi, Anthony and Foster, Charles and Golding, Laurence and Hsu, Jeffrey and Le Noac'h, Alain and Li, Haonan and McDonell, Kyle and Muennighoff, Niklas and Ociepa, Chris and Phang, Jason and Reynolds, Laria and Schoelkopf, Hailey and Skowron, Aviya and Sutawika, Lintang and Tang, Eric and Thite, Anish and Wang, Ben and Wang, Kevin and Zou, Andy},
  title        = {A framework for few-shot language model evaluation},
  month        = 07,
  year         = 2024,
  publisher    = {Zenodo},
  version      = {v0.4.3},
  doi          = {10.5281/zenodo.12608602},
  url          = {https://zenodo.org/records/12608602}
}
@misc{zhang2024lmmsevalrealitycheckevaluation,
      title={LMMs-Eval: Reality Check on the Evaluation of Large Multimodal Models}, 
      author={Kaichen Zhang and Bo Li and Peiyuan Zhang and Fanyi Pu and Joshua Adrian Cahyono and Kairui Hu and Shuai Liu and Yuanhan Zhang and Jingkang Yang and Chunyuan Li and Ziwei Liu},
      year={2024},
      eprint={2407.12772},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.12772}, 
}

@misc{lmms-eval2024,
    title={LMMs-Eval: Accelerating the Development of Large Multimoal Models},
    url={https://github.com/EvolvingLMMs-Lab/lmms-eval},
    author={Bo Liand Peiyuan Zhangand Kaichen Zhangand Fanyi Puand Xinrun Duand Yuhao Dongand Haotian Liuand Yuanhan Zhangand Ge Zhangand Chunyuan Li and Ziwei Liu},
    publisher    = {Zenodo},
    version      = {v0.1.0},
    month={March},
    year={2024}
}


@article{lu2021codexglue,
  title={Codexglue: A machine learning benchmark dataset for code understanding and generation},
  author={Lu, Shuai and Guo, Daya and Ren, Shuo and Huang, Junjie and Svyatkovskiy, Alexey and Blanco, Ambrosio and Clement, Colin and Drain, Dawn and Jiang, Daxin and Tang, Duyu and others},
  journal={arXiv preprint arXiv:2102.04664},
  year={2021}
}





@article{masry2024chartgemma,
  title={ChartGemma: Visual Instruction-tuning for Chart Reasoning in the Wild},
  author={Masry, Ahmed and Thakkar, Megh and Bajaj, Aayush and Kartha, Aaryaman and Hoque, Enamul and Joty, Shafiq},
  journal={arXiv preprint arXiv:2407.04172},
  year={2024}
}
@inproceedings{rahman2023chartsumm,
  title={ChartSumm: A Comprehensive Benchmark for Automatic Chart Summarization of Long and Short Summaries.},
  author={Rahman, Raian and Hasan, Rizvi and Al Farhad, Abdullah and Laskar, Md Tahmid Rahman and Ashmafee, Md Hamjajul and Kamal, Abu Raihan Mostofa},
  booktitle={Canadian AI},
  year={2023}
}
@inproceedings{methani2020plotqa,
  title={Plotqa: Reasoning over scientific plots},
  author={Methani, Nitesh and Ganguly, Pritha and Khapra, Mitesh M and Kumar, Pratyush},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={1527--1536},
  year={2020}
}
@article{kahou2017figureqa,
  title={Figureqa: An annotated figure dataset for visual reasoning},
  author={Kahou, Samira Ebrahimi and Michalski, Vincent and Atkinson, Adam and K{\'a}d{\'a}r, {\'A}kos and Trischler, Adam and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1710.07300},
  year={2017}
}
@book{rousseau2023pattern,
  title={Pattern Recognition, Computer Vision, and Image Processing. ICPR 2022 International Workshops and Challenges: Montreal, QC, Canada, August 21--25, 2022, Proceedings, Part I},
  author={Rousseau, Jean-Jacques and Kapralos, Bill},
  volume={13643},
  year={2023},
  publisher={Springer Nature}
}
@article{team2024gemini,
  title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author={Team, Gemini and Georgiev, Petko and Lei, Ving Ian and Burnell, Ryan and Bai, Libin and Gulati, Anmol and Tanzer, Garrett and Vincent, Damien and Pan, Zhufeng and Wang, Shibo and others},
  journal={arXiv preprint arXiv:2403.05530},
  year={2024}
}
@article{beyer2024paligemma,
  title={Paligemma: A versatile 3b vlm for transfer},
  author={Beyer, Lucas and Steiner, Andreas and Pinto, Andr{\'e} Susano and Kolesnikov, Alexander and Wang, Xiao and Salz, Daniel and Neumann, Maxim and Alabdulmohsin, Ibrahim and Tschannen, Michael and Bugliarello, Emanuele and others},
  journal={arXiv preprint arXiv:2407.07726},
  year={2024}
}
@inproceedings{lee2023pix2struct,
  title={Pix2struct: Screenshot parsing as pretraining for visual language understanding},
  author={Lee, Kenton and Joshi, Mandar and Turc, Iulia Raluca and Hu, Hexiang and Liu, Fangyu and Eisenschlos, Julian Martin and Khandelwal, Urvashi and Shaw, Peter and Chang, Ming-Wei and Toutanova, Kristina},
  booktitle={International Conference on Machine Learning},
  pages={18893--18912},
  year={2023},
  organization={PMLR}
}
@article{liu2022matcha,
  title={Matcha: Enhancing visual language pretraining with math reasoning and chart derendering},
  author={Liu, Fangyu and Piccinno, Francesco and Krichene, Syrine and Pang, Chenxi and Lee, Kenton and Joshi, Mandar and Altun, Yasemin and Collier, Nigel and Eisenschlos, Julian Martin},
  journal={arXiv preprint arXiv:2212.09662},
  year={2022}
}
@article{masry2024chartinstruct,
  title={ChartInstruct: Instruction Tuning for Chart Comprehension and Reasoning},
  author={Masry, Ahmed and Shahmohammadi, Mehrad and Parvez, Md Rizwan and Hoque, Enamul and Joty, Shafiq},
  journal={arXiv preprint arXiv:2403.09028},
  year={2024}
}
@article{balaji2018chart,
  title={Chart-text: A fully automated chart image descriptor},
  author={Balaji, Abhijit and Ramanathan, Thuvaarakkesh and Sonathi, Venkateshwarlu},
  journal={arXiv preprint arXiv:1812.10636},
  year={2018}
}
@inproceedings{gao2012view,
  title={View: Visual information extraction widget for improving chart images accessibility},
  author={Gao, Jinglun and Zhou, Yin and Barner, Kenneth E},
  booktitle={Proceedings of the IEEE International Conference on Image Processing},
  pages={2865--2868},
  year={2012},
  organization={IEEE}
}
@inproceedings{sreevalsan2021tensor,
  title={Tensor fields for data extraction from chart images: bar charts and scatter plots},
  author={Sreevalsan-Nair, Jaya and Dadhich, Komal and Daggubati, Siri Chandana},
  booktitle={Topological Methods in Data Analysis and Visualization VI: Theory, Applications, and Software},
  pages={219--241},
  year={2021},
  organization={Springer}
}
@inproceedings{choi2019visualizing,
  title={Visualizing for the non-visual: Enabling the visually impaired to use visualization},
  author={Choi, Jinho and Jung, Sanghun and Park, Deok Gun and Choo, Jaegul and Elmqvist, Niklas},
  booktitle={Computer Graphics Forum},
  volume={38},
  number={3},
  pages={249--260},
  year={2019},
  organization={Wiley Online Library}
}
@inproceedings{jung2017chartsense,
  title={Chartsense: Interactive data extraction from chart images},
  author={Jung, Daekyoung and Kim, Wonjae and Song, Hyunjoo and Hwang, Jeong-in and Lee, Bongshin and Kim, Bohyoung and Seo, Jinwook},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  pages={6706--6717},
  year={2017}
}
@inproceedings{poco2017reverse,
  title={Reverse-engineering visualizations: Recovering visual encodings from chart images},
  author={Poco, Jorge and Heer, Jeffrey},
  booktitle={Computer Graphics Forum},
  volume={36},
  number={3},
  pages={353--363},
  year={2017},
  organization={Wiley Online Library}
}
@inproceedings{savva2011revision,
  title={Revision: Automated classification, analysis and redesign of chart images},
  author={Savva, Manolis and Kong, Nicholas and Chhajta, Arti and Fei-Fei, Li and Agrawala, Maneesh and Heer, Jeffrey},
  booktitle={Proceedings of the Annual ACM Symposium on User Interface Software and Technology},
  pages={393--402},
  year={2011}
}

@inproceedings{alam2023seechart,
  title={SeeChart: enabling accessible visualizations through interactive natural language interface for people with visual impairments},
  author={Alam, Md Zubair Ibne and Islam, Shehnaz and Hoque, Enamul},
  booktitle={Proceedings of the 28th International Conference on Intelligent User Interfaces},
  pages={46--64},
  year={2023}
}
@inproceedings{luo2021chartocr,
  title={Chartocr: Data extraction from charts images via a deep hybrid framework},
  author={Luo, Junyu and Li, Zekun and Wang, Jinpeng and Lin, Chin-Yew},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={1917--1925},
  year={2021}
}

@article{huang2023lvlms,
  title={Do lvlms understand charts? analyzing and correcting factual errors in chart captioning},
  author={Huang, Kung-Hsiang and Zhou, Mingyang and Chan, Hou Pong and Fung, Yi R and Wang, Zhenhailong and Zhang, Lingyu and Chang, Shih-Fu and Ji, Heng},
  journal={arXiv preprint arXiv:2312.10160},
  year={2023}
}
@article{masry2023unichart,
  title={Unichart: A universal vision-language pretrained model for chart comprehension and reasoning},
  author={Masry, Ahmed and Kavehzadeh, Parsa and Do, Xuan Long and Hoque, Enamul and Joty, Shafiq},
  journal={arXiv preprint arXiv:2305.14761},
  year={2023}
}
@article{tang2023vistext,
  title={Vistext: A benchmark for semantically rich chart captioning},
  author={Tang, Benny J and Boggust, Angie and Satyanarayan, Arvind},
  journal={arXiv preprint arXiv:2307.05356},
  year={2023}
}
@inproceedings{voigt2023vist5,
  title={VIST5: An adaptive, retrieval-augmented language model for visualization-oriented dialog},
  author={Voigt, Henrik and Carvalhais, Nuno and Meuschke, Monique and Reichstein, Markus and Zarrie, Sina and Lawonn, Kai},
  booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={70--81},
  year={2023},
  organization={Association for Computational Linguistics}
}
@inproceedings{masson2023chartdetective,
  title={Chartdetective: Easy and accurate interactive data extraction from complex vector charts},
  author={Masson, Damien and Malacria, Sylvain and Vogel, Daniel and Lank, Edward and Casiez, G{\'e}ry},
  booktitle={Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  pages={1--17},
  year={2023}
}
@inproceedings{cheng2023chartreader,
  title={Chartreader: A unified framework for chart derendering and comprehension without heuristic rules},
  author={Cheng, Zhi-Qi and Dai, Qi and Hauptmann, Alexander G},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={22202--22213},
  year={2023}
}
@article{bajic2022data,
  title={Data extraction of circular-shaped and grid-like chart images},
  author={Baji{\'c}, Filip and Job, Josip},
  journal={Journal of imaging},
  volume={8},
  number={5},
  pages={136},
  year={2022},
  publisher={MDPI}
}

@article{cao2024graphinsight,
  title={Graphinsight: Unlocking insights in large language models for graph structure understanding},
  author={Cao, Yukun and Han, Shuo and Gao, Zengyi and Ding, Zezhong and Xie, Xike and Zhou, S Kevin},
  journal={arXiv preprint arXiv:2409.03258},
  year={2024}
}

@article{chung2024scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Yunxuan and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={70},
  pages={1--53},
  year={2024}
}
@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}
@article{sun2311graph,
  title={Graph prompt learning: A comprehensive survey and beyond. arXiv 2023},
  author={Sun, X and Zhang, J and Wu, X and Cheng, H and Xiong, Y and Li, J},
  journal={arXiv preprint arXiv:2311.16534}
}
@article{chen2022large,
  title={Large language models are few (1)-shot table reasoners},
  author={Chen, Wenhu},
  journal={arXiv preprint arXiv:2210.06710},
  year={2022}
}

